# BeyBlade GO: An Augmented Reality BeyBlade Game

![ReadMe Banner](https://user-images.githubusercontent.com/97734029/191584268-1b593aff-2492-4099-8b44-00040cd469b1.png)

BeyBlade GO (the name was of course inspired by Pokemon GO) is a multiplayer augmented reality game, based on the popular anime series BeyBlade. According to Wikipedia, Beyblade is a line of spinning-top toys originally developed by Takara, first released in Japan in July 1999, along with its debut series. There are multiple kinds of BeyBlades, but we'll be having two in this game:

1. **Attack Type:** These Beyblades specialize in attacking other Beyblades. They battle fiercely and try to knock out the other Beyblade as fast as they can but at the cost of having poor stamina. 
2. **Defense Type:** These Beyblades have more stamina as compared to Attack-type Beyblades. They attack less fiercely resulting in less damage to the opponent. However, they can also withstand the attacks of the opponent much more as compared to Attack-type Beyblades.

## ⬇️ Download the Game

``` 
Make sure that your device is compatible with ARCore. 
Also, make sure to give Camera permissions to the app. It is disabled by default. 
```

For android versions 6.0 and above, you can download the game from here: [Download APK](https://github.com/lightlessdays/AR-BeyBlade/blob/main/Assets/build.apk?raw=true)

```
Make sure that your device is compatible with ARKit. 
Also, give camera permissions to the app.
```

Since I do not have a Mac, I cannot add the iOS files here. If you have one, you may add it here and submit a pull request.

```
This game has been made with Unity 2019.
If you are using Unity 2020 or above, make sure to change your Unity Version.
```

You can download the Unity Project from here: [Download UnityProject.zip](https://github.com/lightlessdays/BeyBlade-AR/releases/download/v1.0/UnityProject.zip)

## 💻 About Photon

This game uses Photon PUN for networking. Photon Unity Networking (PUN) is a Unity package for multiplayer games. Flexible matchmaking gets your players into rooms where objects can be synced over the network. The PUN package wraps up three layers of APIs:

👉 The highest level is the PUN code, which implements Unity-specific features like networked objects, RPCs and so on.

👉 The second level contains the logic to work with Photon servers, do matchmaking, callbacks and such. This is the Realtime API.

👉 The lowest level is made up of DLL files, which contain the de/serialization, protocols and such.

## 🎮 About AR Foundation

AR Foundation is a cross-platform framework that allows you to build augmented reality experiences once, then build for either Android or iOS devices. AR Foundation is a set of MonoBehaviours and APIs for dealing with devices that support the following concepts:

👉 Device tracking: track the device's position and orientation in physical space.

👉 Plane detection: detect horizontal and vertical surfaces.

👉 Point clouds, also known as feature points.

👉 Anchor: an arbitrary position and orientation that the device tracks.

👉 Light estimation: estimates for average color temperature and brightness in physical space.

👉 Environment probe: a means for generating a cube map to represent a particular area of the physical environment.

👉 Face tracking: detect and track human faces.

👉 2D image tracking: detect and track 2D images.

👉 3D object tracking: detect 3D objects.

👉 Meshing: generate triangle meshes that correspond to the physical space.

👉 Body tracking: 2D and 3D representations of humans recognized in physical space.

👉 Collaborative participants: track the position and orientation of other devices in a shared AR experience.

👉 Human segmentation: determines a stencil texture and depth map of humans detected in the camera image.

👉 Raycast: queries physical surroundings for detected planes and feature points.

👉 Pass-through video: optimized rendering of mobile camera image onto touch screen as the background for AR content.

👉 Session management: manipulation of the platform-level configuration automatically when AR Features are enable or disabled.

👉 Occlusion: allows for occlusion of virtual content by detected environmental depth (environment occlusion) or by detected human depth (human occlusion).

## 📱 Screenshots
<center>
<img src="Screenshots/1.jpg" width=50%>
<img src="Screenshots/2.jpg" width=50%>
<img src="Screenshots/3.jpg" width=50%></center>
